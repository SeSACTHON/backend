apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ecoeco-alerts
  namespace: default
  labels:
    prometheus: ecoeco
    role: alert-rules
spec:
  groups:
    - name: api-services
      interval: 30s
      rules:
        # API 응답 시간 알림
        - alert: HighAPILatency
          expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
          for: 5m
          labels:
            severity: warning
            component: api
          annotations:
            summary: "High API latency detected"
            description: "API {{ $labels.service }} has 95th percentile latency > 1s (current: {{ $value }}s)"

        # API 에러율 알림
        - alert: HighAPIErrorRate
          expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
          for: 5m
          labels:
            severity: critical
            component: api
          annotations:
            summary: "High API error rate"
            description: "API {{ $labels.service }} error rate > 5% (current: {{ $value | humanizePercentage }})"

        # API Pod Down
        - alert: APIPodDown
          expr: up{job=~".*-api"} == 0
          for: 2m
          labels:
            severity: critical
            component: api
          annotations:
            summary: "API Pod is down"
            description: "API pod {{ $labels.pod }} in {{ $labels.namespace }} is down"

        # API 높은 CPU 사용률
        - alert: HighAPICPUUsage
          expr: rate(container_cpu_usage_seconds_total{container=~".*-api"}[5m]) > 0.8
          for: 10m
          labels:
            severity: warning
            component: api
          annotations:
            summary: "High API CPU usage"
            description: "API {{ $labels.container }} CPU usage > 80% (current: {{ $value | humanizePercentage }})"

        # API 높은 메모리 사용률
        - alert: HighAPIMemoryUsage
          expr: container_memory_usage_bytes{container=~".*-api"} / container_spec_memory_limit_bytes{container=~".*-api"} > 0.9
          for: 10m
          labels:
            severity: warning
            component: api
          annotations:
            summary: "High API memory usage"
            description: "API {{ $labels.container }} memory usage > 90% (current: {{ $value | humanizePercentage }})"

    - name: worker-services
      interval: 30s
      rules:
        # Worker Task 실패율
        - alert: HighWorkerTaskFailureRate
          expr: rate(celery_task_failed_total[5m]) / rate(celery_task_total[5m]) > 0.1
          for: 5m
          labels:
            severity: critical
            component: worker
          annotations:
            summary: "High worker task failure rate"
            description: "Worker {{ $labels.worker }} task failure rate > 10% (current: {{ $value | humanizePercentage }})"

        # Worker Queue 크기 증가
        - alert: WorkerQueueSizeHigh
          expr: rabbitmq_queue_messages_ready > 1000
          for: 10m
          labels:
            severity: warning
            component: worker
          annotations:
            summary: "Worker queue size is high"
            description: "Queue {{ $labels.queue }} has {{ $value }} pending messages"

        # Worker Pod Down
        - alert: WorkerPodDown
          expr: up{job=~".*-worker"} == 0
          for: 2m
          labels:
            severity: critical
            component: worker
          annotations:
            summary: "Worker Pod is down"
            description: "Worker pod {{ $labels.pod }} in {{ $labels.namespace }} is down"

        # Worker Task 처리 시간 증가
        - alert: HighWorkerTaskDuration
          expr: histogram_quantile(0.95, rate(celery_task_duration_seconds_bucket[5m])) > 60
          for: 10m
          labels:
            severity: warning
            component: worker
          annotations:
            summary: "High worker task duration"
            description: "Worker {{ $labels.worker }} 95th percentile task duration > 60s (current: {{ $value }}s)"

    - name: infrastructure
      interval: 30s
      rules:
        # RabbitMQ Down
        - alert: RabbitMQDown
          expr: up{job="rabbitmq"} == 0
          for: 2m
          labels:
            severity: critical
            component: rabbitmq
          annotations:
            summary: "RabbitMQ is down"
            description: "RabbitMQ pod {{ $labels.pod }} is down"

        # PostgreSQL Down
        - alert: PostgreSQLDown
          expr: up{job="postgresql"} == 0
          for: 2m
          labels:
            severity: critical
            component: postgresql
          annotations:
            summary: "PostgreSQL is down"
            description: "PostgreSQL pod {{ $labels.pod }} is down"

        # Redis Down
        - alert: RedisDown
          expr: up{job="redis"} == 0
          for: 2m
          labels:
            severity: critical
            component: redis
          annotations:
            summary: "Redis is down"
            description: "Redis pod {{ $labels.pod }} is down"

        # PostgreSQL Connection Pool 사용률
        - alert: HighPostgreSQLConnectionPoolUsage
          expr: pg_stat_database_numbackends / pg_settings_max_connections > 0.8
          for: 10m
          labels:
            severity: warning
            component: postgresql
          annotations:
            summary: "High PostgreSQL connection pool usage"
            description: "PostgreSQL connection pool usage > 80% (current: {{ $value | humanizePercentage }})"

        # Redis 메모리 사용률
        - alert: HighRedisMemoryUsage
          expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.9
          for: 10m
          labels:
            severity: warning
            component: redis
          annotations:
            summary: "High Redis memory usage"
            description: "Redis memory usage > 90% (current: {{ $value | humanizePercentage }})"

    - name: node-health
      interval: 30s
      rules:
        # Node CPU 사용률
        - alert: HighNodeCPUUsage
          expr: (1 - avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m]))) > 0.85
          for: 10m
          labels:
            severity: warning
            component: node
          annotations:
            summary: "High node CPU usage"
            description: "Node {{ $labels.instance }} CPU usage > 85% (current: {{ $value | humanizePercentage }})"

        # Node 메모리 사용률
        - alert: HighNodeMemoryUsage
          expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.9
          for: 10m
          labels:
            severity: warning
            component: node
          annotations:
            summary: "High node memory usage"
            description: "Node {{ $labels.instance }} memory usage > 90% (current: {{ $value | humanizePercentage }})"

        # Node 디스크 사용률
        - alert: HighNodeDiskUsage
          expr: (1 - (node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.lxcfs"} / node_filesystem_size_bytes{fstype!~"tmpfs|fuse.lxcfs"})) > 0.85
          for: 10m
          labels:
            severity: warning
            component: node
          annotations:
            summary: "High node disk usage"
            description: "Node {{ $labels.instance }} disk usage > 85% on {{ $labels.mountpoint }} (current: {{ $value | humanizePercentage }})"

        # Node Down
        - alert: NodeDown
          expr: up{job="node-exporter"} == 0
          for: 5m
          labels:
            severity: critical
            component: node
          annotations:
            summary: "Node is down"
            description: "Node {{ $labels.instance }} is down or unreachable"

