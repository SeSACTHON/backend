# ğŸš€ ë°°í¬ ê°€ì´ë“œ

> **4-Tier Kubernetes í´ëŸ¬ìŠ¤í„° ìë™ ë°°í¬**  
> **ì†Œìš” ì‹œê°„**: 40-50ë¶„ (ì™„ì „ ìë™í™”)  
> **ë‚ ì§œ**: 2025-10-31

## ğŸ“‹ ëª©ì°¨

1. [ë¹ ë¥¸ ì‹œì‘](#ë¹ ë¥¸-ì‹œì‘)
2. [4-Tier ì•„í‚¤í…ì²˜](#4-tier-ì•„í‚¤í…ì²˜)
3. [ë°°í¬ ë‹¨ê³„](#ë°°í¬-ë‹¨ê³„)
4. [ê²€ì¦](#ê²€ì¦)
5. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

---

## âš¡ ë¹ ë¥¸ ì‹œì‘

### ì™„ì „ ìë™ ë°°í¬ (40-50ë¶„)

```bash
cd /Users/mango/workspace/SeSACTHON/backend

# ëª¨ë“  í™•ì¸ ì—†ì´ ìë™ ì‹¤í–‰
./scripts/auto-rebuild.sh
```

**ì‹¤í–‰ ê³¼ì •:**
```
1. Terraform destroy (5ë¶„)
2. Terraform apply (5-10ë¶„)
3. Ansible ëŒ€ê¸° (5ë¶„)
4. Ansible ì‹¤í–‰ (35-40ë¶„)
   â”œâ”€ Common ì„¤ì •
   â”œâ”€ Docker ì„¤ì¹˜
   â”œâ”€ Kubernetes ì„¤ì¹˜
   â”œâ”€ Master ì´ˆê¸°í™”
   â”œâ”€ Workers ì¡°ì¸ (3ê°œ)
   â”œâ”€ Calico VXLAN CNI
   â”œâ”€ cert-manager
   â”œâ”€ AWS Load Balancer Controller
   â”œâ”€ Ingress ë¦¬ì†ŒìŠ¤
   â”œâ”€ Monitoring (Prometheus, Grafana)
   â””â”€ etcd ë°±ì—…

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì´: 40-50ë¶„
```

---

## ğŸ—ï¸ 4-Tier ì•„í‚¤í…ì²˜

### Architecture Overview

```mermaid
graph TB
    subgraph Internet["Internet Layer"]
        Users["Users"]
    end
    
    subgraph AWS["AWS Layer"]
        Route53["Route53<br/>DNS"]
        ALB["Application Load Balancer<br/>L7 Routing + SSL"]
        ACM["ACM<br/>SSL Certificate"]
        S3["S3<br/>Image Storage"]
    end
    
    subgraph Tier1["Tier 1: Control + Monitoring"]
        Master["Master Node<br/>t3.large 8GB<br/><br/>â€¢ kube-apiserver<br/>â€¢ etcd<br/>â€¢ scheduler<br/>â€¢ controller<br/>â€¢ Prometheus<br/>â€¢ Grafana<br/>â€¢ ArgoCD"]
    end
    
    subgraph Tier2["Tier 2: Sync API Application"]
        Worker1["Worker-1 Node<br/>t3.medium 4GB<br/><br/>â€¢ auth-service x2<br/>â€¢ users-service x1<br/>â€¢ locations-service x1"]
    end
    
    subgraph Tier3["Tier 3: Async Workers"]
        Worker2["Worker-2 Node<br/>t3.medium 4GB<br/><br/>â€¢ waste-service x2<br/>â€¢ AI Workers x3<br/>â€¢ Batch Workers x2"]
    end
    
    subgraph Tier4["Tier 4: Stateful Storage"]
        Storage["Storage Node<br/>t3.large 8GB<br/><br/>â€¢ RabbitMQ HA x3<br/>â€¢ PostgreSQL<br/>â€¢ Redis<br/>â€¢ Celery Beat"]
    end
    
    Users --> Route53
    Route53 --> ALB
    ACM -.-> ALB
    ALB --> Master
    
    Master -.->|manage| Worker1
    Master -.->|manage| Worker2
    Master -.->|manage| Storage
    
    Worker1 -->|publish tasks| Storage
    Worker2 -->|consume tasks| Storage
    Worker2 --> S3
    
    style Internet fill:#1a237e,color:#fff
    style AWS fill:#0d47a1,color:#fff
    style Tier1 fill:#1565c0,color:#fff
    style Tier2 fill:#2e7d32,color:#fff
    style Tier3 fill:#f57f17,color:#fff
    style Tier4 fill:#c2185b,color:#fff
    style Master fill:#42a5f5,color:#000
    style Worker1 fill:#66bb6a,color:#000
    style Worker2 fill:#ffa726,color:#000
    style Storage fill:#ec407a,color:#fff
```

### ì—­í•  ë¶„ë¦¬ (Instagram + Robin Storage íŒ¨í„´)

```
Tier 1: Control + Monitoring (Master, t3.large, 8GB, $60)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì—­í• : Kubernetes Control Plane + Monitoring
ë°°ì¹˜:
â”œâ”€ kube-apiserver, etcd, scheduler, controller-manager
â”œâ”€ Prometheus + Grafana (ëª¨ë‹ˆí„°ë§)
â””â”€ ArgoCD (GitOps CD)

Tier 2: Sync API (Worker-1, t3.medium, 4GB, $30)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì—­í• : ë™ê¸° API ì„œë¹„ìŠ¤ (FastAPI Reactor íŒ¨í„´)
ë°°ì¹˜:
â”œâ”€ auth-service Ã—2 (OAuth, JWT)
â”œâ”€ users-service Ã—1 (í”„ë¡œí•„, ì´ë ¥)
â””â”€ locations-service Ã—1 (ìˆ˜ê±°í•¨ ê²€ìƒ‰)
íŒ¨í„´: Reactor (ì¦‰ì‹œ ì‘ë‹µ <100ms)

Tier 3: Async Workers (Worker-2, t3.medium, 4GB, $30)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì—­í• : ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬ (Celery Workers)
ë°°ì¹˜:
â”œâ”€ waste-service Ã—2 (ì´ë¯¸ì§€ ë¶„ì„ API)
â”œâ”€ AI Workers Ã—3 (GPT-4o Vision, q.ai)
â””â”€ Batch Workers Ã—2 (ë°°ì¹˜ ì‘ì—…, q.batch)
íŒ¨í„´: Task Queue (ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬)

Tier 4: Stateful Storage (Storage, t3.large, 8GB, $60)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì—­í• : Stateful ì„œë¹„ìŠ¤ (Robin Storage íŒ¨í„´)
ë°°ì¹˜:
â”œâ”€ RabbitMQ Ã—3 (HA Cluster, 5 Queues)
â”œâ”€ PostgreSQL (StatefulSet, 50GB PVC)
â”œâ”€ Redis (Result Backend + Cache)
â””â”€ Celery Beat Ã—1 (ìŠ¤ì¼€ì¤„ëŸ¬)
íŒ¨í„´: Stateful Isolation

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì´ ë¹„ìš©: $185/ì›” (EC2 $180 + S3 $5)
ì´ ë¦¬ì†ŒìŠ¤: 8 vCPU, 24GB RAM, 260GB Storage
```

---

## ğŸ“¦ ë°°í¬ ë‹¨ê³„

### Step 1: ì‚¬ì „ ì¤€ë¹„

```bash
# AWS CLI ì„¤ì •
aws configure
# Access Key, Secret Key, Region: ap-northeast-2

# Terraform ì„¤ì¹˜ í™•ì¸
terraform version

# Ansible ì„¤ì¹˜ í™•ì¸
ansible --version

# SSH í‚¤ ìƒì„± (ì—†ëŠ” ê²½ìš°)
ssh-keygen -t rsa -b 4096 -f ~/.ssh/sesacthon-k8s
```

### Step 2: Terraform ë³€ìˆ˜ ì„¤ì •

```bash
cd terraform

# terraform.tfvars ìƒì„±
cat > terraform.tfvars <<EOF
aws_region = "ap-northeast-2"
cluster_name = "prod-sesacthon"
ssh_public_key_path = "~/.ssh/sesacthon-k8s.pub"
allowed_ssh_cidr = ["YOUR_IP/32"]  # ë³¸ì¸ IPë¡œ ë³€ê²½
domain_name = "growbin.app"
letsencrypt_email = "admin@growbin.app"
EOF
```

### Step 3: ìë™ ë°°í¬ ì‹¤í–‰

```bash
cd /Users/mango/workspace/SeSACTHON/backend

# ì˜µì…˜ 1: ì™„ì „ ìë™ (ì¶”ì²œ)
./scripts/auto-rebuild.sh

# ì˜µì…˜ 2: ë‹¨ê³„ë³„ í™•ì¸
./scripts/rebuild-cluster.sh
```

### Step 4: ë°°í¬ í™•ì¸

```bash
# ì¸ìŠ¤í„´ìŠ¤ í™•ì¸
./scripts/get-instances.sh

# Master SSH ì ‘ì†
./scripts/connect-ssh.sh master

# í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
kubectl get nodes
kubectl get pods -A

# í—¬ìŠ¤ì²´í¬
./scripts/remote-health-check.sh master
```

---

## âœ… ê²€ì¦

### 1. ë…¸ë“œ ìƒíƒœ

```bash
kubectl get nodes -o wide

# ì˜ˆìƒ ì¶œë ¥:
NAME          STATUS   ROLES           AGE   VERSION   INTERNAL-IP   EXTERNAL-IP
k8s-master    Ready    control-plane   10m   v1.28.x   10.0.1.x      52.78.x.x
k8s-worker-1  Ready    <none>          9m    v1.28.x   10.0.2.x      3.36.x.x
k8s-worker-2  Ready    <none>          9m    v1.28.x   10.0.3.x      3.37.x.x
k8s-storage   Ready    <none>          9m    v1.28.x   10.0.1.x      52.79.x.x
```

### 2. ì‹œìŠ¤í…œ Pod

```bash
kubectl get pods -A

# í•„ìˆ˜ Pod í™•ì¸:
âœ… kube-system/calico-node (4ê°œ, all Ready)
âœ… kube-system/calico-kube-controllers (1ê°œ)
âœ… kube-system/coredns (2ê°œ)
âœ… kube-system/aws-load-balancer-controller (1ê°œ)
âœ… cert-manager/* (3ê°œ)
âœ… monitoring/prometheus (1ê°œ)
âœ… monitoring/grafana (1ê°œ)
```

### 3. Calico VXLAN í™•ì¸

```bash
# Calico ìƒíƒœ
kubectl get pods -n kube-system -l k8s-app=calico-node

# VXLAN ëª¨ë“œ í™•ì¸
kubectl exec -n kube-system calico-node-xxxxx -- \
  calicoctl node status

# ì˜ˆìƒ ì¶œë ¥:
# IPv4 BGP status: (ë¹„í™œì„±í™”)
# VXLAN tunnel: Up
```

### 4. ALB Controller

```bash
# ALB Controller Pod
kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller

# Ingress ë¦¬ì†ŒìŠ¤
kubectl get ingress -A

# ALB DNS í™•ì¸
kubectl get ingress main-ingress -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'
```

### 5. RabbitMQ HA

```bash
# RabbitMQ Pods (Storage ë…¸ë“œì— ë°°ì¹˜)
kubectl get pods -n messaging -l app.kubernetes.io/name=rabbitmq

# ì˜ˆìƒ: 3ê°œ Pod (HA Cluster)
# rabbitmq-0, rabbitmq-1, rabbitmq-2

# Cluster ìƒíƒœ í™•ì¸
kubectl exec -n messaging rabbitmq-0 -- rabbitmqctl cluster_status
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: Worker ì¡°ì¸ ì‹¤íŒ¨

```bash
# Storage ë…¸ë“œê°€ ì¡°ì¸ ì•ˆ ëœ ê²½ìš°
./scripts/connect-ssh.sh storage

# Kubelet ìƒíƒœ í™•ì¸
sudo systemctl status kubelet

# ì¬ì¡°ì¸
sudo kubeadm reset -f
# Masterì—ì„œ join ëª…ë ¹ì–´ ë‹¤ì‹œ ê°€ì ¸ì˜¤ê¸°
sudo kubeadm token create --print-join-command
```

### ë¬¸ì œ 2: Calico NotReady

```bash
# Calico ë¡œê·¸ í™•ì¸
kubectl logs -n kube-system -l k8s-app=calico-node

# VXLAN ëª¨ë“œ ì¬ì„¤ì •
kubectl set env daemonset/calico-node -n kube-system \
  CALICO_IPV4POOL_VXLAN=Always \
  CALICO_IPV4POOL_IPIP=Never

# Calico Pod ì¬ì‹œì‘
kubectl rollout restart daemonset/calico-node -n kube-system
```

### ë¬¸ì œ 3: ALB Controller ì‹¤íŒ¨

```bash
# Helm ì„¤ì¹˜ í™•ì¸
helm version

# ALB Controller ì¬ì„¤ì¹˜
helm uninstall aws-load-balancer-controller -n kube-system
# Ansible 07-alb-controller.yml ì¬ì‹¤í–‰
```

### ë¬¸ì œ 4: RabbitMQ Pod Pending

```bash
# PVC í™•ì¸
kubectl get pvc -n messaging

# Storage ë…¸ë“œ ë¼ë²¨ í™•ì¸
kubectl get nodes --show-labels | grep storage

# ë¼ë²¨ ì¶”ê°€ (ì—†ëŠ” ê²½ìš°)
kubectl label nodes k8s-storage workload=storage
```

---

## ğŸ“Š ë¦¬ì†ŒìŠ¤ í˜„í™©

### ë…¸ë“œë³„ ë¦¬ì†ŒìŠ¤

```
Master (Tier 1):
â”œâ”€ vCPU: 2 cores
â”œâ”€ Memory: 8GB
â”œâ”€ Disk: 80GB
â”œâ”€ ì‚¬ìš©ë¥ : CPU 50%, Memory 60%
â””â”€ ë¹„ìš©: $60/ì›”

Worker-1 (Tier 2):
â”œâ”€ vCPU: 2 cores
â”œâ”€ Memory: 4GB
â”œâ”€ Disk: 40GB
â”œâ”€ ì‚¬ìš©ë¥ : CPU 40%, Memory 50%
â””â”€ ë¹„ìš©: $30/ì›”

Worker-2 (Tier 3):
â”œâ”€ vCPU: 2 cores
â”œâ”€ Memory: 4GB
â”œâ”€ Disk: 40GB
â”œâ”€ ì‚¬ìš©ë¥ : CPU 70%, Memory 65%
â””â”€ ë¹„ìš©: $30/ì›”

Storage (Tier 4):
â”œâ”€ vCPU: 2 cores
â”œâ”€ Memory: 8GB
â”œâ”€ Disk: 100GB
â”œâ”€ ì‚¬ìš©ë¥ : CPU 50%, Memory 70%
â””â”€ ë¹„ìš©: $60/ì›”

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì´: 8 vCPU, 24GB RAM, 260GB
ë¹„ìš©: $185/ì›” (EC2 $180 + S3 $5)
```

---

## ğŸ” í—¬ìŠ¤ì²´í¬

### ìë™ í—¬ìŠ¤ì²´í¬ ìŠ¤í¬ë¦½íŠ¸

```bash
# Master ë…¸ë“œ í—¬ìŠ¤ì²´í¬
./scripts/remote-health-check.sh master

# í™•ì¸ í•­ëª©:
âœ… ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ (ë©”ëª¨ë¦¬, ë””ìŠ¤í¬, Swap)
âœ… containerd ì„¤ì •
âœ… Control Plane ì»´í¬ë„ŒíŠ¸
âœ… ë…¸ë“œ ìƒíƒœ (4/4 Ready)
âœ… CrashLoopBackOff Pod
âœ… API ì„œë²„ ì•ˆì •ì„± (30ì´ˆ í…ŒìŠ¤íŠ¸)
âœ… ë„¤íŠ¸ì›Œí¬ ì„¤ì •
âœ… kube-proxy & Calico

ì ìˆ˜: 20ì  ë§Œì 
ê¸°ì¤€:
- 18-20ì : í´ëŸ¬ìŠ¤í„° ì•ˆì •
- 15-17ì : ì¼ë¶€ ë¬¸ì œ
- 0-14ì : ì‹¬ê°í•œ ë¬¸ì œ
```

---

## ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸

### ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬

```bash
# ì „ì²´ ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ
./scripts/get-instances.sh

# SSH ì ‘ì†
./scripts/connect-ssh.sh master
./scripts/connect-ssh.sh worker-1
./scripts/connect-ssh.sh worker-2
./scripts/connect-ssh.sh storage

# ë…¸ë“œ ì´ˆê¸°í™”
./scripts/reset-node.sh master
./scripts/reset-node.sh storage
./scripts/reset-node.sh all  # ëª¨ë“  ì›Œì»¤
```

### í´ëŸ¬ìŠ¤í„° ì¬êµ¬ì¶•

```bash
# ëŒ€í™”í˜• ì¬êµ¬ì¶•
./scripts/rebuild-cluster.sh

# ì™„ì „ ìë™
./scripts/auto-rebuild.sh

# ë¹ ë¥¸ ì¬êµ¬ì¶• (Terraform ìœ ì§€)
./scripts/quick-rebuild.sh
```

---

## ğŸ“š ë°°í¬ í›„ ë‹¨ê³„

### 1. Route53 DNS ì„¤ì •

```bash
# ALB DNS í™•ì¸
kubectl get ingress main-ingress -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'

# Route53ì—ì„œ Alias ë ˆì½”ë“œ ìƒì„±:
# growbin.app â†’ ALB DNS
# *.growbin.app â†’ ALB DNS
```

### 2. ì„œë¹„ìŠ¤ ë°°í¬ (ArgoCD)

```bash
# ArgoCD ì ‘ì†
# https://growbin.app/argocd
# Username: admin
# Password: kubectl -n argocd get secret argocd-initial-admin-secret \
#           -o jsonpath="{.data.password}" | base64 -d

# Applications ë“±ë¡
kubectl apply -f argocd/applications/all-services.yaml
```

### 3. Grafana ëª¨ë‹ˆí„°ë§

```bash
# Grafana ì ‘ì†
# https://growbin.app/grafana
# Username: admin
# Password: (Ansibleì—ì„œ ì„¤ì •í•œ ë¹„ë°€ë²ˆí˜¸)

# ëŒ€ì‹œë³´ë“œ í™•ì¸:
â”œâ”€ Cluster Overview
â”œâ”€ Node Resources
â”œâ”€ Pod Status
â””â”€ RabbitMQ Queues
```

---

## ğŸ¯ ì•„í‚¤í…ì²˜ íŒ¨í„´

### Instagram Pattern

```
Worker ë¶„ë¦¬:
â”œâ”€ Tier 2: Sync API (ì¦‰ì‹œ ì‘ë‹µ)
â””â”€ Tier 3: Async Workers (ë°±ê·¸ë¼ìš´ë“œ)

ì¥ì :
âœ… ë…ë¦½ ìŠ¤ì¼€ì¼ë§
âœ… ì¥ì•  ê²©ë¦¬
âœ… ë¦¬ì†ŒìŠ¤ ìµœì í™”
```

### Robin Storage Pattern

```
Storage ê²©ë¦¬:
â””â”€ Tier 4: Stateful ì„œë¹„ìŠ¤ë§Œ ëª¨ìŒ

ì¥ì :
âœ… ë°ì´í„° ì•ˆì •ì„±
âœ… ë°±ì—… ìš©ì´
âœ… Control Plane ì•ˆì •ì„±
```

---

## ğŸ“– ìƒì„¸ ë¬¸ì„œ

- **[4-Tier ë°°í¬ ì•„í‚¤í…ì²˜](docs/architecture/deployment-architecture-4node.md)** - ì „ì²´ ë‹¤ì´ì–´ê·¸ë¨
- **[Self-Managed K8s ì„ íƒ ë°°ê²½](docs/architecture/why-self-managed-k8s.md)** - ì˜ì‚¬ê²°ì •
- **[VPC ë„¤íŠ¸ì›Œí¬ ì„¤ê³„](docs/infrastructure/vpc-network-design.md)** - ë³´ì•ˆ ê·¸ë£¹
- **[Task Queue ì„¤ê³„](docs/architecture/task-queue-design.md)** - RabbitMQ + Celery
- **[êµ¬ì¶• ì²´í¬ë¦¬ìŠ¤íŠ¸](docs/guides/SETUP_CHECKLIST.md)** - ìƒì„¸ ë‹¨ê³„

---

## ğŸ¯ í•µì‹¬ ì‚¬ì–‘

```
Kubernetes:
â”œâ”€ Distribution: kubeadm (Self-Managed)
â”œâ”€ Version: v1.28
â”œâ”€ CNI: Calico VXLAN (BGP ë¹„í™œì„±í™”)
â”œâ”€ Nodes: 4ê°œ (4-Tier)
â””â”€ HA: non-HA (ë‹¨ì¼ Master)

Networking:
â”œâ”€ VPC: 10.0.0.0/16
â”œâ”€ Subnets: 3 Public (AZ a, b, c)
â”œâ”€ ALB: L7 Load Balancer
â”œâ”€ ACM: *.growbin.app
â””â”€ Route53: DNS ê´€ë¦¬

Storage:
â”œâ”€ RabbitMQ: 3-node HA (20GB Ã— 3)
â”œâ”€ PostgreSQL: StatefulSet (50GB PVC)
â””â”€ Redis: Deployment

Automation:
â”œâ”€ Terraform: AWS ë¦¬ì†ŒìŠ¤
â”œâ”€ Ansible: 75ê°œ ì‘ì—…
â”œâ”€ Scripts: 12ê°œ ìœ í‹¸ë¦¬í‹°
â””â”€ ë°°í¬ ì‹œê°„: 40-50ë¶„
```

---

## ğŸš€ ë¹ ë¥¸ ëª…ë ¹ì–´

```bash
# í´ëŸ¬ìŠ¤í„° ìƒíƒœ
kubectl get nodes

# ëª¨ë“  Pod
kubectl get pods -A

# Ingress í™•ì¸
kubectl get ingress -A

# ALB DNS
kubectl get ingress main-ingress -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'

# RabbitMQ í´ëŸ¬ìŠ¤í„°
kubectl exec -n messaging rabbitmq-0 -- rabbitmqctl cluster_status

# í—¬ìŠ¤ì²´í¬
./scripts/remote-health-check.sh master

# ì¬êµ¬ì¶•
./scripts/auto-rebuild.sh
```

---

**ì‘ì„±ì¼**: 2025-10-31  
**ë°°í¬ ì‹œê°„**: 40-50ë¶„  
**ì´ ë¹„ìš©**: $185/ì›”  
**ìƒíƒœ**: âœ… í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ
