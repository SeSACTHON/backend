# ì´ì½”ì—ì½”(EcoÂ²) Observability #1: ë¡œê¹… íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

> **ì‹œë¦¬ì¦ˆ**: EcoÂ² Observability Enhancement  
> **ì‘ì„±ì¼**: 2025-12-17  
> **ìˆ˜ì •ì¼**: 2025-12-18  
> **íƒœê·¸**: `#Kubernetes` `#ECK` `#Elasticsearch` `#Kibana` `#FluentBit` `#ECS`

---

## ğŸ“‹ ê°œìš”

ì´ë²ˆ ê¸€ì—ì„œëŠ” ECK(Elastic Cloud on Kubernetes) Operatorë¥¼ ì‚¬ìš©í•˜ì—¬ EFK ìŠ¤íƒì„ êµ¬ì¶•í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ë‹¤ë£¹ë‹ˆë‹¤.

### êµ¬ì¶• ìˆœì„œ

1. ì¸í”„ë¼ í”„ë¡œë¹„ì €ë‹ (Terraform/Ansible)
2. ECK Operator ì„¤ì¹˜
3. Elasticsearch CR ë°°í¬
4. Kibana CR ë°°í¬
5. Fluent Bit DaemonSet ë°°í¬
6. External Secrets ì—°ë™

---

## ğŸ—ï¸ Observability ì•„í‚¤í…ì²˜ êµ¬ì¡°

### ì „ì²´ êµ¬ì¡°ë„

```mermaid
flowchart TB
    subgraph cluster["Kubernetes Cluster (16 Nodes)"]
        subgraph workers["Worker Nodes (API ì„œë¹„ìŠ¤)"]
            auth[auth-api<br/>+ Envoy Sidecar]
            char[character-api<br/>+ Envoy Sidecar]
            chat[chat-api<br/>+ Envoy Sidecar]
            
            auth --> |stdout/JSON| logs1["/var/log/containers/*.log"]
            char --> |stdout/JSON| logs1
            chat --> |stdout/JSON| logs1
        end
        
        subgraph fb["Fluent Bit (DaemonSet Ã— 16)"]
            tail["tail INPUT"]
            k8s["kubernetes FILTER"]
            ecs["ECS Lua FILTER"]
            esout["es OUTPUT"]
            
            logs1 --> |tail| tail
            tail --> k8s
            k8s --> ecs
            ecs --> esout
        end
        
        subgraph logging["k8s-logging Node (ì „ìš©)"]
            subgraph eck["ECK Operator"]
                es["Elasticsearch<br/>StatefulSet<br/>â€¢ 4GB JVM Heap<br/>â€¢ 50GB PVC (gp3)"]
                kb["Kibana<br/>Deployment<br/>â€¢ 1GB Memory<br/>â€¢ ko-KR Locale"]
            end
        end
        
        subgraph istio["istio-system"]
            jaeger["Jaeger<br/>Trace Storage"]
            kiali["Kiali<br/>Service Mesh UI"]
        end
        
        esout --> |HTTP 9200| es
        es <--> kb
    end
    
    user((User)) --> |HTTPS| kb
    
    style es fill:#f9f,stroke:#333
    style kb fill:#9ff,stroke:#333
    style fb fill:#ff9,stroke:#333
```

### ì»´í¬ë„ŒíŠ¸ êµ¬ì„± ë° ì—­í• 

| ì»´í¬ë„ŒíŠ¸ | ë°°í¬ ë°©ì‹ | ì—­í•  | ë¦¬ì†ŒìŠ¤ |
|----------|----------|------|--------|
| **Fluent Bit** | DaemonSet (16 ë…¸ë“œ) | ë¡œê·¸ ìˆ˜ì§‘, íŒŒì‹±, ECS ë³€í™˜, ì „ì†¡ | ~64MB/ë…¸ë“œ |
| **Elasticsearch** | StatefulSet (ECK CR) | ë¡œê·¸ ì €ì¥, ì¸ë±ì‹±, ê²€ìƒ‰ | 4GB heap, 50GB disk |
| **Kibana** | Deployment (ECK CR) | ì‹œê°í™”, ëŒ€ì‹œë³´ë“œ, ê²€ìƒ‰ UI | 1GB |
| **ECK Operator** | Deployment | ES/Kibana CRD ê´€ë¦¬ | 200MB |

### í˜„ì¬ í´ëŸ¬ìŠ¤í„° ìƒíƒœ

| í•­ëª© | ìƒíƒœ |
|------|------|
| Fluent Bit DaemonSet | 16/16 Ready |
| Elasticsearch | green (1 node) |
| ì¼ì¼ ë¡œê·¸ëŸ‰ | ~500K+ docs/day |
| ì¸ë±ìŠ¤ í¬ê¸° | ~420MB/day |

---

## ğŸ¯ Fluent Bit: ì—ì´ì „íŠ¸ ê¸°ë°˜ ìˆ˜ì§‘ ì „ëµ

### ì™œ Fluent Bitì„ ì—ì´ì „íŠ¸(DaemonSet)ë¡œ ì„ íƒí–ˆëŠ”ê°€?

#### 1. Kubernetes ë„¤ì´í‹°ë¸Œ ì„¤ê³„

```mermaid
flowchart LR
    subgraph optA["ì˜µì…˜ A: ì¤‘ì•™ ì§‘ì¤‘í˜• (Logstash)"]
        direction LR
        podA[Pod] --> |stdout| nodeA[Node Log]
        nodeA --> |???| filebeat[Filebeat]
        filebeat --> logstash[Logstash]
        logstash --> esA[ES]
    end
    
    subgraph optB["ì˜µì…˜ B: ì—ì´ì „íŠ¸ ê¸°ë°˜ (Fluent Bit) âœ…"]
        direction LR
        podB[Pod] --> |stdout| nodeB[Node Log]
        nodeB --> |local read| fluentbit[Fluent Bit]
        fluentbit --> esB[ES]
    end
    
    style optB fill:#e8f5e9,stroke:#4caf50
```

| ë¹„êµ í•­ëª© | ì¤‘ì•™ ì§‘ì¤‘í˜• (Logstash) | ì—ì´ì „íŠ¸ ê¸°ë°˜ (Fluent Bit) |
|----------|----------------------|---------------------------|
| ë„¤íŠ¸ì›Œí¬ | ì›ê²© ìˆ˜ì§‘ í•„ìš” | ë¡œì»¬ íŒŒì¼ ì½ê¸° |
| í™•ì¥ì„± | ë…¸ë“œ ì¶”ê°€ ì‹œ ì„¤ì • ë³€ê²½ | DaemonSet ìë™ ë°°í¬ |
| ì¥ì•  ê²©ë¦¬ | SPOF ìœ„í—˜ | ë…¸ë“œë³„ ë…ë¦½ |

#### 2. ê²½ëŸ‰ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©

```mermaid
xychart-beta
    title "16ê°œ ë…¸ë“œ í´ëŸ¬ìŠ¤í„° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ"
    x-axis ["Fluent Bit", "Fluentd", "Logstash HA"]
    y-axis "Total RAM (MB)" 0 --> 5000
    bar [1024, 640, 4096]
```

| ì†”ë£¨ì…˜ | ë…¸ë“œë‹¹ ë©”ëª¨ë¦¬ | ì´ ì‚¬ìš©ëŸ‰ (16ë…¸ë“œ) |
|--------|-------------|-------------------|
| **Fluent Bit** | ~64MB | ~1GB |
| Fluentd | ~40MB | ~640MB |
| Logstash HA | 2GB Ã— 2 | ~4GB |

#### 3. ECS í‘œì¤€ í•„ë“œ ìë™ ë§¤í•‘

í˜„ì¬ êµ¬í˜„ëœ Lua ìŠ¤í¬ë¦½íŠ¸ë¡œ K8s ë©”íƒ€ë°ì´í„°ë¥¼ ECS í•„ë“œë¡œ ìë™ ë³€í™˜:

```lua
-- service.name ë§¤í•‘ ìš°ì„ ìˆœìœ„
-- 1. ì•± ë¡œê·¸ì˜ ê¸°ì¡´ service.name ìœ ì§€
-- 2. k8s_labels_app
-- 3. k8s_labels_app.kubernetes.io/name
-- 4. k8s_labels_k8s-app
-- 5. k8s_container_name
```

---

## ğŸ”„ í–¥í›„ Kafka ì „í™˜ì„ ìœ„í•œ ì„¤ê³„

[EDA ì „í™˜ ë¡œë“œë§µ](https://rooftopsnow.tistory.com/27)ì— ë”°ë¼, EDA ë„ì… ì‹œ **Fluent Bit â†’ Kafka â†’ Logstash â†’ ES** êµ¬ì¡°ë¡œ ì „í™˜í•©ë‹ˆë‹¤.

### Phase 1 (í˜„ì¬) vs Phase 2 (EDA) ë¹„êµ

```mermaid
flowchart LR
    subgraph phase1["Phase 1: EFK (í˜„ì¬)"]
        fb1[Fluent Bit<br/>DaemonSet] --> |ì§ì ‘ ì „ì†¡| es1[Elasticsearch]
    end
    
    subgraph phase2["Phase 2: EFKL + Kafka (EDA ë„ì… ì‹œ)"]
        fb2[Fluent Bit<br/>DaemonSet] --> kafka[Kafka<br/>ë²„í¼]
        kafka --> logstash[Logstash]
        logstash --> |Saga trace_id<br/>CDC íŒŒì‹±| es2[Elasticsearch]
    end
    
    style phase1 fill:#fff3e0,stroke:#ff9800
    style phase2 fill:#e3f2fd,stroke:#2196f3
```

### Fluent Bit output ë³€ê²½ë§Œìœ¼ë¡œ ì „í™˜

```yaml
# Phase 1: Elasticsearch ì§ì ‘ ì „ì†¡ (í˜„ì¬)
[OUTPUT]
    Name            es
    Match           kube.*
    Host            eco2-logs-es-http.logging.svc.cluster.local
    Port            9200

# Phase 2: Kafkaë¡œ ì „ì†¡ (outputë§Œ ë³€ê²½)
[OUTPUT]
    Name            kafka
    Match           kube.*
    Brokers         kafka.kafka.svc.cluster.local:9092
    Topics          logs-raw
    Format          json
```

---

## ğŸ”§ Step 1: ì¸í”„ë¼ í”„ë¡œë¹„ì €ë‹

### Terraform - ë¡œê¹… ì „ìš© ë…¸ë“œ ì¶”ê°€

```hcl
# terraform/instances.tf
resource "aws_instance" "logging" {
  count         = 1
  ami           = data.aws_ami.ubuntu.id
  instance_type = "t3.large"  # 8GB RAM
  
  root_block_device {
    volume_size = 100
    volume_type = "gp3"
  }
  
  tags = {
    Name     = "k8s-logging"
    Role     = "logging"
    Workload = "logging"
  }
}
```

### Ansible - ë…¸ë“œ ì„¤ì •

```yaml
# ansible/playbooks/03-worker-join.yml
- name: Configure logging node
  hosts: logging
  tasks:
    - name: Apply node labels
      command: >
        kubectl label node k8s-logging
        workload=logging --overwrite
        
    - name: Apply node taints
      command: >
        kubectl taint node k8s-logging
        domain=observability:NoSchedule --overwrite
```

---

## ğŸ”§ Step 2: ECK Operator ì„¤ì¹˜

### ArgoCD Application

```yaml
# clusters/dev/apps/62-eck-operator.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: eck-operator
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "62"
spec:
  project: default
  source:
    chart: eck-operator
    repoURL: https://helm.elastic.co
    targetRevision: 2.11.0
    helm:
      values: |
        installCRDs: true
        resources:
          requests:
            memory: 150Mi
            cpu: 100m
          limits:
            memory: 200Mi
            cpu: 200m
  destination:
    server: https://kubernetes.default.svc
    namespace: elastic-system
```

---

## ğŸ”§ Step 3: Elasticsearch CR ë°°í¬

### Elasticsearch Custom Resource

```yaml
# workloads/logging/base/elasticsearch.yaml
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: eco2-logs
  namespace: logging
spec:
  version: 8.11.0
  nodeSets:
  - name: default
    count: 1
    config:
      node.store.allow_mmap: false
      indices.memory.index_buffer_size: 20%
      discovery.seed_hosts: []
      cluster.initial_master_nodes:
      - eco2-logs-es-default-0
    
    podTemplate:
      spec:
        nodeSelector:
          workload: logging
        tolerations:
        - key: domain
          operator: Equal
          value: observability
          effect: NoSchedule
        
        containers:
        - name: elasticsearch
          env:
          - name: ES_JAVA_OPTS
            value: "-Xms4g -Xmx4g"
          resources:
            requests:
              memory: 5Gi
              cpu: 500m
            limits:
              memory: 5Gi
              cpu: 2000m
        
        initContainers:
        - name: sysctl
          securityContext:
            privileged: true
            runAsUser: 0
          command: ['sh', '-c', 'sysctl -w vm.max_map_count=262144']
    
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data
      spec:
        accessModes: [ReadWriteOnce]
        storageClassName: gp3
        resources:
          requests:
            storage: 50Gi
  
  http:
    tls:
      selfSignedCertificate:
        disabled: true
```

### ECKê°€ ìë™ ìƒì„±í•˜ëŠ” ë¦¬ì†ŒìŠ¤

| ë¦¬ì†ŒìŠ¤ ì¢…ë¥˜ | ì´ë¦„ | ìš©ë„ |
|-------------|------|------|
| StatefulSet | `eco2-logs-es-default` | ES Pod ê´€ë¦¬ |
| Service | `eco2-logs-es-http` | HTTP ì—”ë“œí¬ì¸íŠ¸ (9200) |
| Service | `eco2-logs-es-transport` | Transport (9300) |
| Secret | `eco2-logs-es-elastic-user` | elastic ì‚¬ìš©ì ë¹„ë°€ë²ˆí˜¸ |

---

## ğŸ”§ Step 4: Kibana CR ë°°í¬

### Kibana Custom Resource

```yaml
# workloads/logging/base/kibana.yaml
apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: eco2-kibana
  namespace: logging
spec:
  version: 8.11.0
  count: 1
  
  elasticsearchRef:
    name: eco2-logs
  
  config:
    server.name: kibana
    server.host: "0.0.0.0"
    server.publicBaseUrl: https://kibana.dev.growbin.app
    i18n.locale: ko-KR
    monitoring.ui.container.elasticsearch.enabled: true
  
  podTemplate:
    spec:
      nodeSelector:
        workload: logging
      tolerations:
      - key: domain
        operator: Equal
        value: observability
        effect: NoSchedule
      containers:
      - name: kibana
        env:
        - name: NODE_OPTIONS
          value: "--max-old-space-size=1024"
        resources:
          requests:
            memory: 1Gi
            cpu: 200m
          limits:
            memory: 1Gi
            cpu: 1000m
  
  http:
    tls:
      selfSignedCertificate:
        disabled: true
```

---

## ğŸ”§ Step 5: Fluent Bit DaemonSet ë°°í¬

### Fluent Bit íŒŒì´í”„ë¼ì¸

```mermaid
flowchart LR
    subgraph input["INPUT"]
        tail["tail<br/>/var/log/containers/*.log"]
    end
    
    subgraph filter["FILTER Chain"]
        cri["CRI Parser<br/>containerd ë¡œê·¸ íŒŒì‹±"]
        k8s["kubernetes<br/>ë©”íƒ€ë°ì´í„° ì¶”ê°€"]
        grep["grep<br/>health probe ì œì™¸"]
        modify["modify<br/>cluster/env ì¶”ê°€"]
        nest["nest<br/>k8s_ prefix"]
        lua["Lua ECS<br/>ECS í•„ë“œ ë§¤í•‘"]
    end
    
    subgraph output["OUTPUT"]
        es["Elasticsearch<br/>Replace_Dots: Off"]
    end
    
    tail --> cri --> k8s --> grep --> modify --> nest --> lua --> es
```

### ì£¼ìš” ì„¤ì •

```yaml
# workloads/logging/base/fluent-bit.yaml (í•µì‹¬ ë¶€ë¶„)
[INPUT]
    Name              tail
    Tag               kube.*
    Path              /var/log/containers/*.log
    Parser            cri  # containerd ëŸ°íƒ€ì„ìš©
    Mem_Buf_Limit     50MB

[FILTER]
    Name                kubernetes
    Match               kube.*
    Merge_Log           On      # JSON ë³‘í•©
    Keep_Log            Off     # ì›ë³¸ log í•„ë“œ ì œê±°
    Labels              On

# ECS í•„ë“œ ìë™ ë§¤í•‘ (Lua ìŠ¤í¬ë¦½íŠ¸)
[FILTER]
    Name          lua
    Match         kube.*
    script        /fluent-bit/etc/ecs-enrichment.lua
    call          enrich_with_ecs_fields

[OUTPUT]
    Name            es
    Match           kube.*
    Host            eco2-logs-es-http.logging.svc.cluster.local
    Logstash_Format On
    Logstash_Prefix logs
    Replace_Dots    Off  # ECS dot notation ìœ ì§€
    Buffer_Size     5MB
```

### ECS Enrichment Lua ìŠ¤í¬ë¦½íŠ¸

```lua
function enrich_with_ecs_fields(tag, timestamp, record)
    -- service.name ë§¤í•‘ (ì•± ë¡œê·¸ ìš°ì„ )
    if not record["service.name"] then
        local service_name = record["k8s_labels_app"]
                          or record["k8s_labels_app.kubernetes.io/name"]
                          or record["k8s_container_name"]
        if service_name then
            record["service.name"] = service_name
        end
    end
    
    -- kubernetes.* ECS í•„ë“œ ë§¤í•‘
    record["kubernetes.namespace"] = record["k8s_namespace_name"]
    record["kubernetes.pod.name"] = record["k8s_pod_name"]
    record["kubernetes.container.name"] = record["k8s_container_name"]
    
    return 1, timestamp, record
end
```

---

## ğŸ”§ Step 6: External Secrets ì—°ë™

### ExternalSecret ë¦¬ì†ŒìŠ¤

```yaml
# workloads/secrets/external-secrets/dev/logging-secrets.yaml
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: elasticsearch-credentials
  namespace: logging
spec:
  refreshInterval: 1h
  secretStoreRef:
    kind: ClusterSecretStore
    name: aws-ssm-store
  data:
  - secretKey: ES_PASSWORD
    remoteRef:
      key: /sesacthon/dev/observability/elasticsearch-password
  target:
    name: elasticsearch-credentials
    template:
      data:
        ES_USER: elastic
        ES_PASSWORD: "{{ .ES_PASSWORD }}"
```

---

## ğŸ”’ NetworkPolicy ì„¤ì •

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-fluent-bit-to-es
  namespace: logging
spec:
  podSelector:
    matchLabels:
      common.k8s.elastic.co/type: elasticsearch
  ingress:
  - from:
    - namespaceSelector: {}
      podSelector:
        matchLabels:
          app: fluent-bit
    ports:
    - port: 9200
```

---

## âœ… ë°°í¬ ê²€ì¦

### 1. ES í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸

```bash
# Pod ìƒíƒœ
kubectl get pods -n logging

# ES í´ëŸ¬ìŠ¤í„° í—¬ìŠ¤
kubectl exec -it eco2-logs-es-default-0 -n logging -- \
  curl -u elastic:$ES_PASSWORD localhost:9200/_cluster/health?pretty
```

### 2. ë¡œê·¸ ì¸ë±ìŠ¤ í™•ì¸

```bash
kubectl exec -it eco2-logs-es-default-0 -n logging -- \
  curl -u elastic:$ES_PASSWORD localhost:9200/_cat/indices?v

# í˜„ì¬ ìƒíƒœ (2025-12-18 ê¸°ì¤€):
# logs-2025.12.17  1.1M docs  421MB
# logs-2025.12.18  500K+ docs  237MB
```

### 3. Kibana ì ‘ì†

```
URL: https://kibana.dev.growbin.app
ID: elastic
PW: <ECKê°€ ìƒì„±í•œ ë¹„ë°€ë²ˆí˜¸>
```

---

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Issue 1: Fluent Bit 401 Unauthorized

```
[error] [output:es:es.0] HTTP status=401 URI=/_bulk
```

**ì›ì¸**: ES ì¸ì¦ ì •ë³´ ëˆ„ë½  
**í•´ê²°**: External Secretsë¡œ `ES_USER`, `ES_PASSWORD` í™˜ê²½ë³€ìˆ˜ ì£¼ì…

### Issue 2: CRI Parser ì˜¤ë¥˜ (containerd)

```
[error] invalid JSON in log field
```

**ì›ì¸**: docker parser ì‚¬ìš© (containerd ëŸ°íƒ€ì„ì—ì„œ)  
**í•´ê²°**: `Parser cri` ì‚¬ìš©

```
[PARSER]
    Name        cri
    Format      regex
    Regex       ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<log>.*)$
```

### Issue 3: ECS dot notation í•„ë“œ ì¸ë±ì‹± ì˜¤ë¥˜

```
mapper_parsing_exception: Could not dynamically add mapping for field [service.name]
```

**ì›ì¸**: ESê°€ dotì„ nested objectë¡œ í•´ì„  
**í•´ê²°**: 
1. Fluent Bit: `Replace_Dots Off`
2. ES Index Template: `subobjects: false`

---

## ğŸ“š ë‹¤ìŒ ê¸€ ë¯¸ë¦¬ë³´ê¸°

**[#2: ë¡œê¹… ì •ì±… ìˆ˜ë¦½]** - Google SRE, Netflix, Uber ë“± ë¹…í…Œí¬ ì‚¬ë¡€ë¥¼ ë¶„ì„í•˜ê³  í”„ë¡œì íŠ¸ì— ë§ëŠ” ë¡œê¹… ì •ì±…ì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.

---

## ğŸ”— ì°¸ê³  ìë£Œ

- [ì´ì½”ì—ì½”(EcoÂ²) EDA ì „í™˜ ë¡œë“œë§µ](https://rooftopsnow.tistory.com/27)
- [ECK Quickstart](https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-quickstart.html)
- [Fluent Bit Kubernetes Filter](https://docs.fluentbit.io/manual/pipeline/filters/kubernetes)
- [Elastic Common Schema (ECS)](https://www.elastic.co/guide/en/ecs/current/index.html)
- [External Secrets Operator](https://external-secrets.io/)
