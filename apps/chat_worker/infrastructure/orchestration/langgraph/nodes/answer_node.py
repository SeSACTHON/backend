"""Answer Generation Node - ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì „ìš©.

ë…¸ë“œ ì±…ì„: ì´ë²¤íŠ¸ ë°œí–‰ + ì„œë¹„ìŠ¤ í˜¸ì¶œ + state ì—…ë°ì´íŠ¸
ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§: AnswerGeneratorServiceì— ìœ„ì„

Prompt Strategy: Hybrid (Global + Local)
- Global: ì´ì½” ìºë¦­í„° ì •ì˜ (ëª¨ë“  Intentì— ê³µí†µ)
- Local: Intentë³„ ì§€ì¹¨ (waste/character/location/general)

References:
- docs/plans/chat-worker-prompt-strategy-adr.md
- docs/foundations/24-multi-agent-prompt-patterns.md
- arxiv:2504.20355 (Local Prompt Optimization)

Clean Architecture:
- Node: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (ì´ íŒŒì¼)
- Service: AnswerGeneratorService (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)
- Port: LLMPort (ìˆœìˆ˜ LLM í˜¸ì¶œ)
"""

from __future__ import annotations

import logging
from typing import TYPE_CHECKING, Any

from chat_worker.application.answer.dto import AnswerContext
from chat_worker.application.answer.services import AnswerGeneratorService
from chat_worker.infrastructure.orchestration.prompts import PromptBuilder

if TYPE_CHECKING:
    from chat_worker.application.ports.events import ProgressNotifierPort
    from chat_worker.application.ports.llm import LLMClientPort

logger = logging.getLogger(__name__)


def create_answer_node(
    llm: "LLMClientPort",
    event_publisher: "ProgressNotifierPort",
):
    """ë‹µë³€ ìƒì„± ë…¸ë“œ íŒ©í† ë¦¬.

    ë…¸ë“œëŠ” thin wrapperë¡œ:
    1. Intentì— ë”°ë¥¸ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„± (Hybrid Pattern)
    2. ì´ë²¤íŠ¸ ë°œí–‰
    3. AnswerGeneratorService í˜¸ì¶œ
    4. state ì—…ë°ì´íŠ¸

    Prompt Strategy:
    - Global: ì´ì½” ìºë¦­í„° ì •ì˜ (ëª¨ë“  Intentì— ê³µí†µ)
    - Local: Intentë³„ ì§€ì¹¨ (waste/character/location/general)
    """
    # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë‹´ë‹¹)
    answer_service = AnswerGeneratorService(llm)

    # í”„ë¡¬í”„íŠ¸ ë¹Œë” (í•˜ì´ë¸Œë¦¬ë“œ í”„ë¡¬í”„íŠ¸)
    prompt_builder = PromptBuilder()

    async def answer_node(state: dict[str, Any]) -> dict[str, Any]:
        job_id = state["job_id"]
        message = state.get("message", "")
        intent = state.get("intent", "general")  # Intent ì¶”ì¶œ
        classification = state.get("classification_result")
        disposal_rules = state.get("disposal_rules")
        character_context = state.get("character_context")
        location_context = state.get("location_context")

        # 1. ì´ë²¤íŠ¸: ì‹œì‘
        await event_publisher.notify_stage(
            task_id=job_id,
            stage="answer",
            status="started",
            progress=70,
            message="ğŸ’­ ë‹µë³€ ê³ ë¯¼ ì¤‘...",
        )

        try:
            # 2. Intent ê¸°ë°˜ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„± (Hybrid Pattern)
            system_prompt = prompt_builder.build(intent)
            logger.debug(f"Built prompt for intent={intent}, length={len(system_prompt)}")

            # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (Serviceì˜ íŒ©í† ë¦¬ ë©”ì„œë“œ ì‚¬ìš©)
            context = AnswerContext(
                classification=classification,
                disposal_rules=disposal_rules.get("data") if disposal_rules else None,
                character_context=character_context,
                location_context=location_context,
                user_input=message,
            )

            # 4. ì„œë¹„ìŠ¤ í˜¸ì¶œ (ìŠ¤íŠ¸ë¦¬ë°)
            answer_parts = []
            async for token in answer_service.generate_stream(
                context=context,
                system_prompt=system_prompt,  # ë™ì  í”„ë¡¬í”„íŠ¸ ì ìš©
            ):
                # í† í° ì´ë²¤íŠ¸ ë°œí–‰ (SSE ìŠ¤íŠ¸ë¦¬ë°)
                await event_publisher.notify_token(
                    task_id=job_id,
                    content=token,
                )
                answer_parts.append(token)

            answer = "".join(answer_parts)

            logger.info(
                "Answer generated",
                extra={
                    "job_id": job_id,
                    "length": len(answer),
                },
            )

            # 4. ì´ë²¤íŠ¸: ì™„ë£Œ
            await event_publisher.notify_stage(
                task_id=job_id,
                stage="answer",
                status="completed",
                progress=100,
            )

            return {**state, "answer": answer}

        except Exception as e:
            logger.error(
                "Answer generation failed",
                extra={"job_id": job_id, "error": str(e)},
            )
            await event_publisher.notify_stage(
                task_id=job_id,
                stage="answer",
                status="failed",
                result={"error": str(e)},
            )
            return {
                **state,
                "answer": "ì£„ì†¡í•´ìš”, ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”! ğŸ™",
            }

    return answer_node
