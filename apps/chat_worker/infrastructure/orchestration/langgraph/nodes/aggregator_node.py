"""Aggregator Node - ë³‘ë ¬ ì‹¤í–‰ ê²°ê³¼ ìˆ˜ì§‘.

Send APIë¡œ ë³‘ë ¬ ì‹¤í–‰ëœ ë…¸ë“œë“¤ì˜ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ê³ 
answer_nodeë¡œ ì „ë‹¬í•  ìµœì¢… stateë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.

LangGraphì˜ Send API íŠ¹ì„±:
- ì—¬ëŸ¬ Sendê°€ ë³‘ë ¬ ì‹¤í–‰ë˜ë©´ ê° ê²°ê³¼ê°€ stateì— ë³‘í•©ë¨
- ì´ ë…¸ë“œëŠ” ë³‘í•©ëœ ê²°ê³¼ë¥¼ ê²€ì¦/ë¡œê¹…í•˜ê³  answerë¡œ ì „ë‹¬

ì—­í• :
1. ë³‘ë ¬ ì‹¤í–‰ ê²°ê³¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
2. ëˆ„ë½ëœ ì»¨í…ìŠ¤íŠ¸ ë¡œê¹… (ë””ë²„ê¹…ìš©)
3. answer_nodeë¥¼ ìœ„í•œ ìµœì¢… state ì •ë¦¬
"""

from __future__ import annotations

import logging
from typing import TYPE_CHECKING, Any

if TYPE_CHECKING:
    from chat_worker.application.ports.events import ProgressNotifierPort

logger = logging.getLogger(__name__)


def create_aggregator_node(
    event_publisher: "ProgressNotifierPort",
):
    """ê²°ê³¼ ìˆ˜ì§‘ ë…¸ë“œ íŒ©í† ë¦¬.

    Args:
        event_publisher: ì´ë²¤íŠ¸ ë°œí–‰ì (SSE)

    Returns:
        aggregator_node í•¨ìˆ˜
    """

    async def aggregator_node(state: dict[str, Any]) -> dict[str, Any]:
        """ë³‘ë ¬ ì‹¤í–‰ ê²°ê³¼ ìˆ˜ì§‘ ë° ì •ë¦¬.

        LangGraph Send APIê°€ ë³‘ë ¬ ì‹¤í–‰ í›„ ìë™ ë³‘í•©í•œ stateë¥¼ ë°›ì•„ì„œ:
        1. ì–´ë–¤ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€ ë¡œê¹…
        2. ëˆ„ë½ëœ í•„ë“œ ê¸°ë³¸ê°’ ì„¤ì •
        3. answer_nodeë¥¼ ìœ„í•œ ìµœì¢… state ë°˜í™˜

        Args:
            state: ë³‘ë ¬ ì‹¤í–‰ í›„ ë³‘í•©ëœ ìƒíƒœ

        Returns:
            ì •ë¦¬ëœ ìƒíƒœ
        """
        job_id = state.get("job_id", "")

        # Progress: ì§‘ê³„ ì‹œì‘
        await event_publisher.notify_stage(
            task_id=job_id,
            stage="aggregate",
            status="started",
            progress=60,
            message="ğŸ“Š ì •ë³´ ì·¨í•© ì¤‘...",
        )

        # ìˆ˜ì§‘ëœ ì»¨í…ìŠ¤íŠ¸ í•„ë“œë“¤
        context_fields = {
            "disposal_rules": "RAG ê²€ìƒ‰ ê²°ê³¼",
            "character_context": "ìºë¦­í„° ì •ë³´",
            "location_context": "ì¥ì†Œ ì •ë³´",
            "web_search_results": "ì›¹ ê²€ìƒ‰ ê²°ê³¼",
            "bulk_waste_context": "ëŒ€í˜•íê¸°ë¬¼ ì •ë³´",
            "recyclable_price_context": "ì¬í™œìš© ì‹œì„¸",
            "weather_context": "ë‚ ì”¨ ì •ë³´",
            "collection_point_context": "ìˆ˜ê±°í•¨ ìœ„ì¹˜",
            "image_generation_context": "ì´ë¯¸ì§€ ìƒì„±",
        }

        # ìˆ˜ì§‘ëœ ì»¨í…ìŠ¤íŠ¸ í™•ì¸
        collected = []
        missing = []

        for field, description in context_fields.items():
            value = state.get(field)
            if value is not None:
                # dictì¸ ê²½ìš° success í•„ë“œ í™•ì¸
                if isinstance(value, dict):
                    if value.get("success", True):  # success ì—†ìœ¼ë©´ Trueë¡œ ê°„ì£¼
                        collected.append(description)
                    else:
                        missing.append(f"{description} (ì‹¤íŒ¨)")
                else:
                    collected.append(description)
            else:
                # Noneì¸ ê²ƒì€ í•´ë‹¹ ë…¸ë“œê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ê²°ê³¼ ì—†ìŒ
                pass  # ì˜ë„ì ìœ¼ë¡œ ì‹¤í–‰ ì•ˆ ëœ ê²ƒì€ ë¡œê¹… ì•ˆ í•¨

        logger.info(
            "Aggregator: contexts collected",
            extra={
                "job_id": job_id,
                "collected_count": len(collected),
                "collected": collected,
            },
        )

        if missing:
            logger.warning(
                "Aggregator: some contexts failed",
                extra={
                    "job_id": job_id,
                    "failed": missing,
                },
            )

        # Progress: ì§‘ê³„ ì™„ë£Œ
        await event_publisher.notify_stage(
            task_id=job_id,
            stage="aggregate",
            status="completed",
            progress=65,
            result={"collected": collected},
        )

        # state ê·¸ëŒ€ë¡œ ë°˜í™˜ (ë³‘í•©ì€ ì´ë¯¸ LangGraphê°€ ì²˜ë¦¬)
        return state

    return aggregator_node


__all__ = ["create_aggregator_node"]
